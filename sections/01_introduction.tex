\section{GIỚI THIỆU (INTRODUCTION)}

\subsection{Đặt vấn đề}
Học tập trực tuyến (E-learning) đã trở thành một phần không thể thiếu của giáo dục hiện đại. Tuy nhiên, một trong những thách thức lớn nhất của hình thức này là thiếu sự tương tác trực tiếp, khiến giáo viên khó nắm bắt được trạng thái cảm xúc và mức độ tập trung của học viên. Việc tự động nhận diện các trạng thái như "Chán nản" (Boredom), "Bối rối" (Confusion) hay "Tập trung" (Engagement) đóng vai trò quan trọng trong việc xây dựng các hệ thống học tập thông minh, có khả năng thích ứng và phản hồi kịp thời để nâng cao hiệu quả giảng dạy.

Gần đây, nghiên cứu của Wang et al.~\cite{wang2025vlm} đã chứng minh tiềm năng của các mô hình ngôn ngữ-thị giác (Vision-Language Models - VLM) trong việc phát hiện cảm xúc học tập của sinh viên thông qua biểu cảm khuôn mặt. Được truyền cảm hứng từ công trình này, nhóm quyết định khai thác khả năng của VLM tiên tiến, cụ thể là Qwen2.5-VL, để giải quyết bài toán nhận diện trạng thái cảm xúc trên tập dữ liệu DAiSEE.

\subsection{Mục tiêu nghiên cứu}
Mục tiêu của đề tài là xây dựng một mô hình học sâu có khả năng phân loại 4 trạng thái cảm xúc của người học dựa trên video ghi hình khuôn mặt, sử dụng tập dữ liệu DAiSEE. Nhóm tập trung khai thác sức mạnh của các mô hình nền tảng đa phương thức (VLM) tiên tiến thay vì các phương pháp CNN truyền thống.

\subsection{Cấu trúc báo cáo}
Báo cáo được chia thành 5 phần chính: Phần I giới thiệu bài toán và động lực nghiên cứu; Phần II mô tả phương pháp đề xuất; Phần III trình bày thiết lập thực nghiệm và phân tích kết quả chi tiết; Phần IV kết luận và hướng phát triển; và cuối cùng là phần Tài liệu tham khảo.
